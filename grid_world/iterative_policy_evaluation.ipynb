{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from grid_world import standard_grid, negative_grid\n",
    "\n",
    "SMALL_ENOUGH = 10e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_values(V, g):\n",
    "    for i in range(g.width):\n",
    "        print('-'*28)\n",
    "        row = ''\n",
    "        for j in range(g.height):\n",
    "            v = V.get((i, j), 0)\n",
    "            if v >= 0:\n",
    "                row += ' {:0.2f} |'.format(v)\n",
    "            else:\n",
    "                row += '{:0.2f} |'.format(v)\n",
    "        print(row)\n",
    "        \n",
    "def print_policy(P, g):\n",
    "    for i in range(g.width):\n",
    "        print('-'*28)\n",
    "        row = ''\n",
    "        for j in range(g.height):\n",
    "            a = P.get((i, j), ' ')\n",
    "            row += '  {}   |'.format(a)\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.0\n",
      "The delta is 0\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.3333333333333333\n",
      "The delta is 0.3333333333333333\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.0\n",
      "The delta is 0.3333333333333333\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=0.0\n",
      "The delta is 0.3333333333333333\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=0.0\n",
      "The delta is 0.3333333333333333\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.5\n",
      "The delta is 0.5\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3333333333333333)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.2777777777777778\n",
      "The delta is 0.5\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=0.0\n",
      "The delta is 0.5\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3333333333333333)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2222222222222222\n",
      "The delta is 0.5\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2222222222222222)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.1111111111111111\n",
      "The delta is 0.1111111111111111\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3333333333333333\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2222222222222222)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.2777777777777778)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.35185185185185186\n",
      "The delta is 0.1111111111111111\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.1111111111111111)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.05555555555555555\n",
      "The delta is 0.1111111111111111\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2777777777777778)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.1388888888888889\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.1388888888888889)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.06944444444444445\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2777777777777778)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.6388888888888888\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2777777777777778\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.1388888888888889)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.6388888888888888)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.35185185185185186)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.3765432098765432\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.05555555555555555)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.06944444444444445)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.0069444444444444475\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2222222222222222\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.1111111111111111)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.35185185185185186)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.25308641975308643\n",
      "The delta is 0.1388888888888889\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.1111111111111111\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.05555555555555555)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.25308641975308643)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.154320987654321\n",
      "The delta is 0.0432098765432099\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.35185185185185186\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.25308641975308643)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3765432098765432)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.3744855967078189\n",
      "The delta is 0.0432098765432099\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.05555555555555555\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.0069444444444444475)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.154320987654321)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.07368827160493828\n",
      "The delta is 0.0432098765432099\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.1388888888888889\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.06944444444444445)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3765432098765432)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.22299382716049382\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.06944444444444445\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.0069444444444444475)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.22299382716049382)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.11496913580246913\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.6388888888888888\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3765432098765432)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.6882716049382716\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3765432098765432\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.22299382716049382)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.6882716049382716)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3744855967078189)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.4285836762688614\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.0069444444444444475\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.07368827160493828)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11496913580246913)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.020640432098765427\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.25308641975308643\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.154320987654321)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3744855967078189)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2599451303155007\n",
      "The delta is 0.08410493827160492\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.154320987654321\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.07368827160493828)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2599451303155007)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.1668167009602195\n",
      "The delta is 0.012495713305898493\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3744855967078189\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2599451303155007)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4285836762688614)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.38954618198445357\n",
      "The delta is 0.015060585276634675\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.07368827160493828\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.020640432098765427)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.1668167009602195)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.07308813443072704\n",
      "The delta is 0.015060585276634675\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.22299382716049382\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11496913580246913)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4285836762688614)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.2717764060356653\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.11496913580246913\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.020640432098765427)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2717764060356653)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.14620841906721535\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.6882716049382716\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4285836762688614)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7142918381344308\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4285836762688614\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.2717764060356653)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7142918381344308)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.38954618198445357)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.4585381420515165\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.020640432098765427\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.07308813443072704)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14620841906721535)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.03656014231824416\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2599451303155007\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.1668167009602195)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.38954618198445357)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.25909017299192194\n",
      "The delta is 0.048782578875171456\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.1668167009602195\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.07308813443072704)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.25909017299192194)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.1660891537113245\n",
      "The delta is 0.0007275472488950108\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.38954618198445357\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.25909017299192194)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4585381420515165)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.39981598968653154\n",
      "The delta is 0.010269807702077971\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.07308813443072704\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.03656014231824416)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.1660891537113245)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.06476450569654016\n",
      "The delta is 0.010269807702077971\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2717764060356653\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14620841906721535)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4585381420515165)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3023732805593659\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.14620841906721535\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.03656014231824416)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3023732805593659)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.16946671143880504\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7142918381344308\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4585381420515165)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7292690710257582\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4585381420515165\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3023732805593659)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7292690710257582)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.39981598968653154)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.4771527804238852\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.03656014231824416\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.06476450569654016)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.16946671143880504)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.05235110287113244\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.25909017299192194\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.1660891537113245)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.39981598968653154)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2554243880082643\n",
      "The delta is 0.030596874523700635\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.1660891537113245\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.06476450569654016)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2554243880082643)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.1600944468524022\n",
      "The delta is 0.005994706858922283\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.39981598968653154\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2554243880082643)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4771527804238852)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.40724279747187364\n",
      "The delta is 0.007426807785342104\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.06476450569654016\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.05235110287113244)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.1600944468524022)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.05387167199063488\n",
      "The delta is 0.010892833705905276\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3023732805593659\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.16946671143880504)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4771527804238852)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3233097459313451\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.16946671143880504\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.05235110287113244)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3233097459313451)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.18783042440123876\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7292690710257582\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4771527804238852)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7385763902119427\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4771527804238852\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3233097459313451)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7385763902119427)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.40724279747187364)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.48970964453838706\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.05235110287113244\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.05387167199063488)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.18783042440123876)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.06697937620530194\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2554243880082643\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.1600944468524022)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.40724279747187364)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2509505497935095\n",
      "The delta is 0.020936465371979185\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.1600944468524022\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.05387167199063488)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2509505497935095)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.15241111089207218\n",
      "The delta is 0.007683335960330023\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.40724279747187364\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2509505497935095)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.48970964453838706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4129196982482925\n",
      "The delta is 0.007683335960330023\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.05387167199063488\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.06697937620530194)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.15241111089207218)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.042715867343385124\n",
      "The delta is 0.011155804647249759\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3233097459313451\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.18783042440123876)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.48970964453838706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3387700344698129\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.18783042440123876\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.06697937620530194)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3387700344698129)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.20287470533755741\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7385763902119427\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.48970964453838706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7448548222691935\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.48970964453838706\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3387700344698129)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7448548222691935)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4129196982482925)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.4988481849957663\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.06697937620530194\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.042715867343385124)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.20287470533755741)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.08007941899708615\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2509505497935095\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.15241111089207218)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4129196982482925)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.24649713754792654\n",
      "The delta is 0.015460288538467815\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.15241111089207218\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.042715867343385124)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.24649713754792654)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.14460650244565584\n",
      "The delta is 0.007804608446416339\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4129196982482925\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.24649713754792654)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4988481849957663)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4174503491492799\n",
      "The delta is 0.007804608446416339\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.042715867343385124\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.08007941899708615)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.14460650244565584)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.03226354172428485\n",
      "The delta is 0.010452325619100276\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3387700344698129\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.20287470533755741)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4988481849957663)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.35086144516666185\n",
      "The delta is 0.012091410696848937\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.20287470533755741\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.08007941899708615)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.35086144516666185)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.215470432081874\n",
      "The delta is 0.012595726744316582\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7448548222691935\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4988481849957663)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7494240924978831\n",
      "The delta is 0.012595726744316582\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4988481849957663\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.35086144516666185)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7494240924978831)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4174503491492799)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5059119622712749\n",
      "The delta is 0.012595726744316582\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.08007941899708615\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.03226354172428485)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.215470432081874)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.09160344517879457\n",
      "The delta is 0.012595726744316582\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.24649713754792654\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.14460650244565584)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4174503491492799)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2423853844321253\n",
      "The delta is 0.012595726744316582\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.14460650244565584\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.03226354172428485)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2423853844321253)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.13732446307820506\n",
      "The delta is 0.007282039367450782\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4174503491492799\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2423853844321253)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5059119622712749)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4211755259463832\n",
      "The delta is 0.007282039367450782\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.03226354172428485\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.09160344517879457)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.13732446307820506)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.022860508949705247\n",
      "The delta is 0.0094030327745796\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.35086144516666185\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.215470432081874)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5059119622712749)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.36069119717657444\n",
      "The delta is 0.009829752009912596\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.215470432081874\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.09160344517879457)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.36069119717657444)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2261473211776845\n",
      "The delta is 0.010676889095810493\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7494240924978831\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5059119622712749)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7529559811356374\n",
      "The delta is 0.010676889095810493\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5059119622712749\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.36069119717657444)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7529559811356374)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4211755259463832)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5116075680861983\n",
      "The delta is 0.010676889095810493\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.09160344517879457\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.022860508949705247)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2261473211776845)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.10164340611398962\n",
      "The delta is 0.010676889095810493\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2423853844321253\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.13732446307820506)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4211755259463832)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.23871631237727392\n",
      "The delta is 0.010676889095810493\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.13732446307820506\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.022860508949705247)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.23871631237727392)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.1307884106634896\n",
      "The delta is 0.006536052414715471\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4211755259463832\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.23871631237727392)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5116075680861983)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.42429708523630816\n",
      "The delta is 0.006536052414715471\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.022860508949705247\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.10164340611398962)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.1307884106634896)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.014572502274749988\n",
      "The delta is 0.008288006674955259\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.36069119717657444\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2261473211776845)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5116075680861983)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3688774446319414\n",
      "The delta is 0.008288006674955259\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2261473211776845\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.10164340611398962)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3688774446319414)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2352604253729655\n",
      "The delta is 0.009113104195280997\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7529559811356374\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5116075680861983)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7558037840430991\n",
      "The delta is 0.009113104195280997\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5116075680861983\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3688774446319414)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7558037840430991)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.42429708523630816)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5163261046371161\n",
      "The delta is 0.009113104195280997\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.10164340611398962\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.014572502274749988)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2352604253729655)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.11034396154910775\n",
      "The delta is 0.009113104195280997\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.23871631237727392\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.1307884106634896)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.42429708523630816)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.23549710847572713\n",
      "The delta is 0.009113104195280997\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.1307884106634896\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.014572502274749988)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.23549710847572713)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.12503480537523856\n",
      "The delta is 0.005753605288251029\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.42429708523630816\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.23549710847572713)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5163261046371161)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.426942998720463\n",
      "The delta is 0.005753605288251029\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.014572502274749988\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11034396154910775)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.12503480537523856)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.007345421913065406\n",
      "The delta is 0.007227080361684582\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3688774446319414\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2352604253729655)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5163261046371161)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.37579326500504084\n",
      "The delta is 0.007227080361684582\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2352604253729655\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11034396154910775)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.37579326500504084)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2430686132770743\n",
      "The delta is 0.00780818790410881\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7558037840430991\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5163261046371161)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7581630523185581\n",
      "The delta is 0.00780818790410881\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5163261046371161\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.37579326500504084)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7581630523185581)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.426942998720463)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5202997720146874\n",
      "The delta is 0.00780818790410881\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.11034396154910775\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.007345421913065406)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2430686132770743)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.11786159568200444\n",
      "The delta is 0.00780818790410881\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.23549710847572713\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.12503480537523856)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.426942998720463)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.23269726888492517\n",
      "The delta is 0.00780818790410881\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.12503480537523856\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.007345421913065406)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.23269726888492517)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.12002134539899528\n",
      "The delta is 0.0050134599762432785\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.426942998720463\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.23269726888492517)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5202997720146874)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4292008343765874\n",
      "The delta is 0.0050134599762432785\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.007345421913065406\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11786159568200444)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.12002134539899528)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=0.001079874858495422\n",
      "The delta is 0.006265547054569984\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.37579326500504084\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2430686132770743)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5202997720146874)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3816841926458808\n",
      "The delta is 0.006265547054569984\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2430686132770743\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.11786159568200444)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3816841926458808)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.24977289416394263\n",
      "The delta is 0.006704280886868336\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7581630523185581\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5202997720146874)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7601498860073437\n",
      "The delta is 0.006704280886868336\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5202997720146874\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3816841926458808)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7601498860073437)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4292008343765874)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5236783043432706\n",
      "The delta is 0.006704280886868336\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.11786159568200444\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.001079874858495422)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.24977289416394263)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.1243465096527236\n",
      "The delta is 0.006704280886868336\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.23269726888492517\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.12002134539899528)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4292008343765874)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.23027350367413596\n",
      "The delta is 0.006704280886868336\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.12002134539899528\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.001079874858495422)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.23027350367413596)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.11567668926631569\n",
      "The delta is 0.004344656132679592\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4292008343765874\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.23027350367413596)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5236783043432706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43113493355637816\n",
      "The delta is 0.004344656132679592\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.001079874858495422\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.1243465096527236)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.11567668926631569)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.004334910193203957\n",
      "The delta is 0.005414785051699379\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3816841926458808\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.24977289416394263)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5236783043432706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3867255992536066\n",
      "The delta is 0.005414785051699379\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.24977289416394263\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.1243465096527236)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3867255992536066)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.25553605445316513\n",
      "The delta is 0.0057631602892224965\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7601498860073437\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5236783043432706)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7618391521716352\n",
      "The delta is 0.0057631602892224965\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5236783043432706\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3867255992536066)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7618391521716352)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43113493355637816)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.52656656166054\n",
      "The delta is 0.0057631602892224965\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.1243465096527236\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.004334910193203957)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.25553605445316513)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.12993548232318455\n",
      "The delta is 0.0057631602892224965\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.23027350367413596\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.11567668926631569)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43113493355637816)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22818058523664583\n",
      "The delta is 0.0057631602892224965\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.11567668926631569\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.004334910193203957)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22818058523664583)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.11192283752172094\n",
      "The delta is 0.0037538517445947495\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43113493355637816\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22818058523664583)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.52656656166054)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43279532547463134\n",
      "The delta is 0.0037538517445947495\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.004334910193203957\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.12993548232318455)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.11192283752172094)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.009006322400731806\n",
      "The delta is 0.004671412207527849\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3867255992536066\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.25553605445316513)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.52656656166054)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.3910513080568525\n",
      "The delta is 0.004671412207527849\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.25553605445316513\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.12993548232318455)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.3910513080568525)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2604933951900185\n",
      "The delta is 0.004957340736853388\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7618391521716352\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.52656656166054)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.76328328083027\n",
      "The delta is 0.004957340736853388\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.52656656166054\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.3910513080568525)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.76328328083027)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43279532547463134)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5290433047872511\n",
      "The delta is 0.004957340736853388\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.12993548232318455\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.009006322400731806)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2604933951900185)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.13474985879537515\n",
      "The delta is 0.004957340736853388\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22818058523664583\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.11192283752172094)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43279532547463134)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22637583734902983\n",
      "The delta is 0.004957340736853388\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.11192283752172094\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.009006322400731806)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22637583734902983)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.10868475747414902\n",
      "The delta is 0.003238080047571923\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43279532547463134\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22637583734902983)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5290433047872511)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43422248914607375\n",
      "The delta is 0.003238080047571923\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.009006322400731806\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.13474985879537515)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.10868475747414902)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.013032550660613068\n",
      "The delta is 0.004026228259881262\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.3910513080568525\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2604933951900185)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5290433047872511)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.39476834998863486\n",
      "The delta is 0.004026228259881262\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2604933951900185\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.13474985879537515)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.39476834998863486)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.264759104392005\n",
      "The delta is 0.0042657092019864895\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.76328328083027\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5290433047872511)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7645216523936256\n",
      "The delta is 0.0042657092019864895\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5290433047872511\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.39476834998863486)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7645216523936256)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43422248914607375)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5311708305094447\n",
      "The delta is 0.0042657092019864895\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.13474985879537515\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.013032550660613068)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.264759104392005)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.13889582752630902\n",
      "The delta is 0.0042657092019864895\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22637583734902983\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.10868475747414902)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43422248914607375)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22482075610935842\n",
      "The delta is 0.0042657092019864895\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.10868475747414902\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.013032550660613068)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22482075610935842)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.10589410272437268\n",
      "The delta is 0.0027906547497763418\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43422248914607375\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22482075610935842)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5311708305094447)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4354500248000287\n",
      "The delta is 0.0027906547497763418\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.013032550660613068\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.13889582752630902)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.10589410272437268)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.016500862400968173\n",
      "The delta is 0.0034683117403551053\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.39476834998863486\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.264759104392005)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5311708305094447)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.39796496745072485\n",
      "The delta is 0.0034683117403551053\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.264759104392005\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.13889582752630902)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.39796496745072485)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.26843039748851694\n",
      "The delta is 0.0036712930965119295\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7645216523936256\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5311708305094447)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7655854152547223\n",
      "The delta is 0.0036712930965119295\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5311708305094447\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.39796496745072485)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7655854152547223)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4354500248000287)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5330001358351586\n",
      "The delta is 0.0036712930965119295\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.13889582752630902\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.016500862400968173)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.26843039748851694)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.14246562994474254\n",
      "The delta is 0.0036712930965119295\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22482075610935842\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.10589410272437268)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4354500248000287)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22348135930811464\n",
      "The delta is 0.0036712930965119295\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.10589410272437268\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.016500862400968173)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22348135930811464)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.10349024845357323\n",
      "The delta is 0.0024038542707994492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4354500248000287\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22348135930811464)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5330001358351586)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43650625884234795\n",
      "The delta is 0.0024038542707994492\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.016500862400968173\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14246562994474254)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.10349024845357323)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.01948769074558466\n",
      "The delta is 0.002986828344616485\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.39796496745072485\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.26843039748851694)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5330001358351586)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.40071526666183777\n",
      "The delta is 0.002986828344616485\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.26843039748851694\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14246562994474254)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.40071526666183777)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.27159044830329016\n",
      "The delta is 0.0031600508147732187\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7655854152547223\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5330001358351586)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7665000679175793\n",
      "The delta is 0.0031600508147732187\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5330001358351586\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.40071526666183777)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7665000679175793)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43650625884234795)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5345738644739216\n",
      "The delta is 0.0031600508147732187\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.14246562994474254\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.01948769074558466)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27159044830329016)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.1455390695244374\n",
      "The delta is 0.0031600508147732187\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22348135930811464\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.10349024845357323)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43650625884234795)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22232799653707508\n",
      "The delta is 0.0031600508147732187\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.10349024845357323\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.01948769074558466)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22232799653707508)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.10142015289574521\n",
      "The delta is 0.002070095557828014\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43650625884234795\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22232799653707508)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5345738644739216)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43741528931228213\n",
      "The delta is 0.002070095557828014\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.01948769074558466\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.1455390695244374)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.10142015289574521)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.022059458314346095\n",
      "The delta is 0.0025717675687614364\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.40071526666183777\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27159044830329016)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5345738644739216)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.4030821563886059\n",
      "The delta is 0.0025717675687614364\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.27159044830329016\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.1455390695244374)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4030821563886059)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.27431061295652165\n",
      "The delta is 0.002720164653231494\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7665000679175793\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5345738644739216)\n",
      "I got reward 0 and now im in state (2, 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7672869322369609\n",
      "The delta is 0.002720164653231494\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5345738644739216\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4030821563886059)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7672869322369609)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43741528931228213)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5359281259792829\n",
      "The delta is 0.002720164653231494\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.1455390695244374\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.022059458314346095)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27431061295652165)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.14818503563543386\n",
      "The delta is 0.002720164653231494\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22232799653707508\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.10142015289574521)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43741528931228213)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.221334954527821\n",
      "The delta is 0.002720164653231494\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.10142015289574521\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.022059458314346095)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.221334954527821)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09963774810673745\n",
      "The delta is 0.0017824047890077632\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43741528931228213\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.221334954527821)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5359281259792829)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43819772381715394\n",
      "The delta is 0.0017824047890077632\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.022059458314346095\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14818503563543386)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09963774810673745)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.024273643764348207\n",
      "The delta is 0.0022141854500021124\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4030821563886059\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27431061295652165)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5359281259792829)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.4051193694679023\n",
      "The delta is 0.0022141854500021124\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.27431061295652165\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.14818503563543386)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4051193694679023)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.27665220255166806\n",
      "The delta is 0.0023415895951464094\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7672869322369609\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5359281259792829)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7679640629896414\n",
      "The delta is 0.0023415895951464094\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5359281259792829\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4051193694679023)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7679640629896414)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43819772381715394)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5370937187582325\n",
      "The delta is 0.0023415895951464094\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.14818503563543386\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.024273643764348207)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27665220255166806)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15046292315800813\n",
      "The delta is 0.0023415895951464094\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.221334954527821\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09963774810673745)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43819772381715394)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.22048000809652782\n",
      "The delta is 0.0023415895951464094\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.09963774810673745\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.024273643764348207)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.22048000809652782)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.0981031821660898\n",
      "The delta is 0.0015345659406476447\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43819772381715394\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.22048000809652782)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5370937187582325)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4388712368872349\n",
      "The delta is 0.0015345659406476447\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.024273643764348207\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15046292315800813)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.0981031821660898)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.026179870495959164\n",
      "The delta is 0.0019062267316109563\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4051193694679023\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.27665220255166806)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5370937187582325)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.40687296065495027\n",
      "The delta is 0.0019062267316109563\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.27665220255166806\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15046292315800813)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.40687296065495027)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2786679419064792\n",
      "The delta is 0.0020157393548111413\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7679640629896414\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5370937187582325)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7685468593791163\n",
      "The delta is 0.0020157393548111413\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5370937187582325\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.40687296065495027)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7685468593791163)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4388712368872349)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.538097018973767\n",
      "The delta is 0.0020157393548111413\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15046292315800813\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.026179870495959164)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2786679419064792)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15242390620121918\n",
      "The delta is 0.0020157393548111413\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.22048000809652782\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.0981031821660898)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4388712368872349)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2197439817596183\n",
      "The delta is 0.0020157393548111413\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.0981031821660898\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.026179870495959164)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2197439817596183)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09678205563182957\n",
      "The delta is 0.001321126534260239\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4388712368872349\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2197439817596183)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.538097018973767)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.43945101240471623\n",
      "The delta is 0.001321126534260239\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.026179870495959164\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15242390620121918)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09678205563182957)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.027820925284694806\n",
      "The delta is 0.0016410547887356422\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.40687296065495027\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2786679419064792)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.538097018973767)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.40838248044012315\n",
      "The delta is 0.0016410547887356422\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2786679419064792\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15242390620121918)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.40838248044012315)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.28040319332067115\n",
      "The delta is 0.0017352514141919517\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7685468593791163\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.538097018973767)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7690485094868835\n",
      "The delta is 0.0017352514141919517\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.538097018973767\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.40838248044012315)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7690485094868835)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43945101240471623)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5389606674439076\n",
      "The delta is 0.0017352514141919517\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15242390620121918\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.027820925284694806)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.28040319332067115)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15411205930268299\n",
      "The delta is 0.0017352514141919517\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2197439817596183\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09678205563182957)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.43945101240471623)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2191103477423711\n",
      "The delta is 0.0017352514141919517\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.09678205563182957\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.027820925284694806)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2191103477423711)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09564471122883814\n",
      "The delta is 0.0011373444029914304\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.43945101240471623\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2191103477423711)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5389606674439076)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4399501065671788\n",
      "The delta is 0.0011373444029914304\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.027820925284694806\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15411205930268299)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09564471122883814)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.029233674036922425\n",
      "The delta is 0.0014127487522276189\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.40838248044012315\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.28040319332067115)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5389606674439076)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.4096819303822894\n",
      "The delta is 0.0014127487522276189\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.28040319332067115\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15411205930268299)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.4096819303822894)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2818969948424862\n",
      "The delta is 0.0014938015218150524\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7690485094868835\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5389606674439076)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7694803337219538\n",
      "The delta is 0.0014938015218150524\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5389606674439076\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4096819303822894)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7694803337219538)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4399501065671788)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5397041235571407\n",
      "The delta is 0.0014938015218150524\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15411205930268299\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.029233674036922425)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2818969948424862)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15556533443970433\n",
      "The delta is 0.0014938015218150524\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2191103477423711\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09564471122883814)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4399501065671788)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.2185648682205531\n",
      "The delta is 0.0014938015218150524\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.09564471122883814\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.029233674036922425)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.2185648682205531)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09466559709181534\n",
      "The delta is 0.000979114137022799\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4399501065671788\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.2185648682205531)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5397041235571407)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4403797517788625\n",
      "The delta is 0.000979114137022799\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.029233674036922425\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15556533443970433)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09466559709181534)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.030449868673944495\n",
      "The delta is 0.0012161946370220708\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4096819303822894\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2818969948424862)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5397041235571407)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.41080055919981345\n",
      "The delta is 0.0012161946370220708\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2818969948424862\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15556533443970433)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.41080055919981345)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.28318294681975886\n",
      "The delta is 0.001285951977272659\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7694803337219538\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5397041235571407)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7698520617785704\n",
      "The delta is 0.001285951977272659\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5397041235571407\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.41080055919981345)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7698520617785704)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4403797517788625)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5403441242524154\n",
      "The delta is 0.001285951977272659\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15556533443970433\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.030449868673944495)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.28318294681975886)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15681640774685168\n",
      "The delta is 0.001285951977272659\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.2185648682205531\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09466559709181534)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4403797517788625)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.21809528177098425\n",
      "The delta is 0.001285951977272659\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.09466559709181534\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.030449868673944495)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.21809528177098425)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09382270654851987\n",
      "The delta is 0.0008428905432954631\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.4403797517788625\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.21809528177098425)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5403441242524154)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.44074961416047703\n",
      "The delta is 0.0008428905432954631\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.030449868673944495\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15681640774685168)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09382270654851987)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.031496850599165904\n",
      "The delta is 0.0010469819252214088\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.41080055919981345\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.28318294681975886)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5403441242524154)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.41176353553608713\n",
      "The delta is 0.0010469819252214088\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.28318294681975886\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15681640774685168)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.41176353553608713)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.2842899716414694\n",
      "The delta is 0.001107024821710545\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7698520617785704\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5403441242524154)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7701720621262077\n",
      "The delta is 0.001107024821710545\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5403441242524154\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.41176353553608713)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7701720621262077)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.44074961416047703)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5408950706075906\n",
      "The delta is 0.001107024821710545\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15681640774685168\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.031496850599165904)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2842899716414694)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.15789341112031766\n",
      "The delta is 0.001107024821710545\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.21809528177098425\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09382270654851987)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.44074961416047703)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.21769103079601426\n",
      "The delta is 0.001107024821710545\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.09382270654851987\n",
      "Im in State (0, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.031496850599165904)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (0, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.21769103079601426)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "The new V[s]=0.09309709009842418\n",
      "The delta is 0.0007256164500956952\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.44074961416047703\n",
      "Im in State (1, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.21769103079601426)\n",
      "I got reward 0 and now im in state (0, 2)\n",
      "Im in State (1, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.5408950706075906)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (1, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.4410680132705254\n",
      "The delta is 0.0007256164500956952\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.031496850599165904\n",
      "Im in State (0, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15789341112031766)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (0, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * 0.09309709009842418)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "The new V[s]=-0.03239816051094674\n",
      "The delta is 0.0009013099117808343\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(1, 3) is a terminal state\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.41176353553608713\n",
      "Im in State (2, 1) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.2842899716414694)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "Im in State (2, 1) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5408950706075906)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "The new V[s]=-0.41259252112453\n",
      "The delta is 0.0009013099117808343\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.2842899716414694\n",
      "Im in State (2, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.15789341112031766)\n",
      "I got reward 0 and now im in state (1, 0)\n",
      "Im in State (2, 0) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.41259252112453)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "The new V[s]=-0.28524296612242384\n",
      "The delta is 0.0009529944809544277\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.7701720621262077\n",
      "Im in State (2, 3) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.5408950706075906)\n",
      "I got reward 0 and now im in state (2, 2)\n",
      "Im in State (2, 3) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (-1 + 1.0 * 0)\n",
      "I got reward -1 and now im in state (1, 3)\n",
      "The new V[s]=-0.7704475353037953\n",
      "The delta is 0.0009529944809544277\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.5408950706075906\n",
      "Im in State (2, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.41259252112453)\n",
      "I got reward 0 and now im in state (2, 1)\n",
      "Im in State (2, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.7704475353037953)\n",
      "I got reward 0 and now im in state (2, 3)\n",
      "Im in State (2, 2) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4410680132705254)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "The new V[s]=-0.5413693565662836\n",
      "The delta is 0.0009529944809544277\n",
      "------------------------------------------------------------\n",
      "OLD V = -0.15789341112031766\n",
      "Im in State (1, 0) and doing action U\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.03239816051094674)\n",
      "I got reward 0 and now im in state (0, 0)\n",
      "Im in State (1, 0) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.5 * (0 + 1.0 * -0.28524296612242384)\n",
      "I got reward 0 and now im in state (2, 0)\n",
      "The new V[s]=-0.1588205633166853\n",
      "The delta is 0.0009529944809544277\n",
      "------------------------------------------------------------\n",
      "OLD V = 0.21769103079601426\n",
      "Im in State (0, 2) and doing action L\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * 0.09309709009842418)\n",
      "I got reward 0 and now im in state (0, 1)\n",
      "Im in State (0, 2) and doing action D\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (0 + 1.0 * -0.4410680132705254)\n",
      "I got reward 0 and now im in state (1, 2)\n",
      "Im in State (0, 2) and doing action R\n",
      "new_v += p_a * (r + gamma * V[grid.current_state()])\n",
      "new_v += 0.3333333333333333 * (1 + 1.0 * 0)\n",
      "I got reward 1 and now im in state (0, 3)\n",
      "The new V[s]=0.21734302560929958\n",
      "The delta is 0.0009529944809544277\n",
      "------------------------------------------------------------\n",
      "OLD V = 0\n",
      "(0, 3) is a terminal state\n",
      "Values for uniform random actions:\n",
      "----------------------------\n",
      "-0.03 | 0.09 | 0.22 | 0.00 |\n",
      "----------------------------\n",
      "-0.16 | 0.00 |-0.44 | 0.00 |\n",
      "----------------------------\n",
      "-0.29 |-0.41 |-0.54 |-0.77 |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "V = {}\n",
    "grid = standard_grid()\n",
    "S = grid.all_states()\n",
    "for state in S:\n",
    "    V[state] = 0\n",
    "gamma = 1.0\n",
    "while True:\n",
    "    delta = 0\n",
    "    for s in S:\n",
    "        print('-'*60)\n",
    "        old_v = V[s]\n",
    "        print('OLD V = {}'.format(old_v))\n",
    "        \n",
    "        if s in grid.actions:\n",
    "            new_v = 0\n",
    "            p_a = 1.0 / len(grid.actions[s])\n",
    "            for a in grid.actions[s]:\n",
    "                print('Im in State {} and doing action {}'.format(s, a))\n",
    "                grid.set_state(s)\n",
    "                r = grid.move(a)\n",
    "                new_v += p_a * (r + gamma * V[grid.current_state()])\n",
    "                print('new_v += p_a * (r + gamma * V[grid.current_state()])')\n",
    "                print('new_v += {} * ({} + {} * {})'.format(p_a, r, gamma, V[grid.current_state()]))\n",
    "                print('I got reward {} and now im in state {}'.format(r, grid.current_state()))\n",
    "            V[s] = new_v\n",
    "            print('The new V[s]={}'.format(V[s]))\n",
    "            delta = max(delta, np.abs(V[s] - old_v))\n",
    "            print('The delta is {}'.format(delta))\n",
    "        else:\n",
    "            print('{} is a terminal state'.format(s))\n",
    "    if delta < SMALL_ENOUGH: break\n",
    "print('Values for uniform random actions:')\n",
    "print_values(V, grid)\n",
    "print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "  R   |  R   |  R   |      |\n",
      "----------------------------\n",
      "  U   |      |  R   |      |\n",
      "----------------------------\n",
      "  U   |  R   |  R   |  U   |\n",
      "Values for fixed policy actions:\n",
      "----------------------------\n",
      " 0.81 | 0.90 | 1.00 | 0.00 |\n",
      "----------------------------\n",
      " 0.73 | 0.00 |-1.00 | 0.00 |\n",
      "----------------------------\n",
      " 0.66 |-0.81 |-0.90 |-1.00 |\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "policy = {\n",
    "    (2, 0): 'U',\n",
    "    (1, 0): 'U',\n",
    "    (0, 0): 'R',\n",
    "    (0, 1): 'R',\n",
    "    (0, 2): 'R',\n",
    "    (1, 2): 'R',\n",
    "    (2, 1): 'R',\n",
    "    (2, 2): 'R',\n",
    "    (2, 3): 'U'\n",
    "}\n",
    "print_policy(policy, grid)\n",
    "\n",
    "V = {}\n",
    "grid = standard_grid()\n",
    "S = grid.all_states()\n",
    "for state in S:\n",
    "    V[state] = 0\n",
    "gamma = 0.9\n",
    "while True:\n",
    "    delta = 0\n",
    "    for s in S:\n",
    "        old_v = V[s]\n",
    "        \n",
    "        if s in grid.actions:\n",
    "            new_v = 0\n",
    "            p_a = 1.0\n",
    "            a = policy[s]\n",
    "            grid.set_state(s)\n",
    "            r = grid.move(a)\n",
    "            V[s]= p_a * (r + gamma * V[grid.current_state()])\n",
    "            delta = max(delta, np.abs(V[s] - old_v))\n",
    "    if delta < SMALL_ENOUGH: break\n",
    "print('Values for fixed policy actions:')\n",
    "print_values(V, grid)\n",
    "print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.001"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SMALL_ENOUGH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      " 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "----------------------------\n",
      " 0.00 | 0.00 | 0.00 | 0.00 |\n",
      "----------------------------\n",
      " 0.00 | 0.00 | 0.00 | 0.00 |\n"
     ]
    }
   ],
   "source": [
    "print_values(V, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
